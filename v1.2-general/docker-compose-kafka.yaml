# COPYRIGHT Hello Corp. All Rights Reserved.
#
# Author: Haley
#

version: '2'

services:
  zookeeper:
    extends:
      file: base/kafka-base.yaml
      service: zookeeper
    container_name: ${ZOOKEEPER_HOST_NAME}
    hostname: ${ZOOKEEPER_HOST_NAME}
    environment:
      # ID在集合中必须是唯一的并且应该有一个值在1-255之间。
      - ZOO_MY_ID=${ZOOKEEPER_ID}
      # 组成ZK集合的服务器列表。客户端使用的列表必须与ZooKeeper服务器列表所拥有的每一个ZK服务器相匹配。
      # 有两个端口号：第一个是追随者用来连接领导者的，第二个是领导人选举。
      - ZOO_SERVERS=server.1=z1:2888:3888 server.2=z2:2888:3888 server.3=z3:2888:3888
    volumes:
       # 数据固化，将zookeeper产生的数据映射到本地，当zookeeper丢失等风险是不至于数据丢失
       - ${ZOOKEEPER_VOLUMES}:/data/
    extra_hosts:
      - z1:${Z1_ADDR}
      - z2:${Z2_ADDR}
      - z3:${Z3_ADDR}
  
  kafka:
    extends:
      file: base/kafka-base.yaml
      service: kafka
    container_name: ${KAFKA_HOST_NAME}
    hostname: ${KAFKA_HOST_NAME}
    environment:
      - KAFKA_BROKER_ID=${KAFKA_BROKER_ID}
      # min.insync.replicas=M --- 设置一个M值（例如1<M<N，查看下面的default.replication.factor）
      # 数据提交时会写入至少M个副本（这些数据然后会被同步并且归属到in-sync副本集合或ISR）。
      # 其它情况，写入操作会返回一个错误。接下来：
      # 1. 如果channel写入的数据多达N-M个副本变的不可用，操作可以正常执行。
      # 2. 如果有更多的副本不可用，Kafka不可以维护一个有M数量的ISR集合，因此Kafka停止接收写操作。Channel只有当同步M个副本后才可以重新可以写。
      - KAFKA_MIN_INSYNC_REPLICAS=2
      - KAFKA_DEFAULT_REPLICATION_FACTOR=3
      # 指向Zookeeper节点的集合，其中包含ZK的集合。
      - KAFKA_ZOOKEEPER_CONNECT=z1:2181,z2:2181,z3:2181
    volumes:
       # kafka数据存储路径，映射到本地
       - ${KAFKA_VOLUMES}:/tmp/kafka-logs/
    extra_hosts:
      - z1:${Z1_ADDR}
      - z2:${Z2_ADDR}
      - z3:${Z3_ADDR}
      - k1:${K1_ADDR}
      - k2:${K2_ADDR}
      - k3:${K3_ADDR}

